# Look at structure
str(quality)
# Prediction function
ROCRpred = prediction(predictTrain, train_dataset$PoorCare)
# Performance function
ROCRperf = performance(ROCRpred, "tpr", "fpr")
# Plot ROC curve
plot(ROCRperf)
# Add colors
plot(ROCRperf, colorize=TRUE)
# Add threshold labels
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
# Prediction on Test Set
predictTest = predict(QualityLog, type = "response", newdata = qualityTest)
# Prediction on Test Set
predictTest = predict(test_dataset, type = "response", newdata = qualityTest)
# Prediction on Test Set
predictTest = predict(Logistic_model, type = "response", newdata = test_dataset)
table(qualityTest$PoorCare,predictTest >= 0.3)
table(test_dataset$PoorCare,predictTest >= 0.3)
# Confusion matrix for threshold of 0.5
comfuse_matrix_1 <- table(train_dataset$PoorCare, predictTrain > 0.5)
#Accuracy
acc_1 <-  (confuse_matrix_1[1]+confuse_matrix_1[4])/sum(confuse_matrix_1)
# Confusion matrix for threshold of 0.5
confuse_matrix_1 <- table(train_dataset$PoorCare, predictTrain > 0.5)
#Accuracy
acc_1 <-  (confuse_matrix_1[1]+confuse_matrix_1[4])/sum(confuse_matrix_1)
acc_1
# Confusion matrix for threshold of 0.7
confuse_matrix_2 <- table(train_dataset$PoorCare, predictTrain > 0.7)
acc_2 <-  (confuse_matrix_2[1]+confuse_matrix_2[4])/sum(confuse_matrix_2)
acc_2
# Confusion matrix for threshold of 0.2
confuse_matrix_3 <- table(train_dataset$PoorCare, predictTrain > 0.2)
acc_3 <-  (confuse_matrix_3[1]+confuse_matrix_3[4])/sum(confuse_matrix_3)
acc_3
?predict()
Logistic_model_2 <- glm(data = train_dataset, PoorCare ~ .,family=binomial)
summary(Logistic_model_2)
# Make predictions on training set (It's give a result in term of probability)
predictTrain = predict(Logistic_model_2, type="response")
summary(predictTrain)
# Make predictions on training set (It's give a result in term of probability)
predictTrain_2 = predict(Logistic_model_2, type="response")
confuse_matrix_1 <- table(train_dataset$PoorCare, predictTrain_2 > 0.5)
#Create Logistic model
Logistic_model <- glm(data = train_dataset, PoorCare ~ OfficeVisits + Narcotics,family=binomial)
# Make predictions on training set (It's give a result in term of probability)
predictTrain = predict(Logistic_model, type="response")
# Confusion matrix for threshold of 0.5
confuse_matrix_1 <- table(train_dataset$PoorCare, predictTrain > 0.5)
acc_1
confuse_matrix_1.2 <- table(train_dataset$PoorCare, predictTrain_2 > 0.5)
acc_1.2 <-  (confuse_matrix_1.2[1]+confuse_matrix_1.2[4])/sum(confuse_matrix_1.2)
acc_1.2
("Model 1 accuracy is" + acc_1)
print("Model 1 accuracy is" , acc_1)
acc_1
concat("Model 1 accuracy(threshold of 0.5) is" , acc_1)
paste("Model 1 accuracy(threshold of 0.5) is" , acc_1)
paste("Model 1 accuracy(threshold of 0.5) is" , round(acc_1,4))
paste("Model 2 accuracy(threshold of 0.5) is" , round(acc_1.2,4))
paste("Model 1 accuracy(threshold of 0.5) is" , round(acc_1,4))
paste("Model 2 accuracy(threshold of 0.5) is" , round(acc_1.2,4))
set.seed(1234)
# Read in dataset
quality = read.csv("quality.csv")
#remove id column
quality <- quality[,-1]
#create INDEX for training data set
splitting_index <- createDataPartition(quality$PoorCare , p=0.75 ,list=F)
View(quality)
#create INDEX for training data set
splitting_index <- createDataPartition(quality$PoorCare , p=0.75 ,list=F)
splitting_index
#create INDEX for training data set
splitting_index <- createDataPartition(quality$PoorCare , p=0.75 ,list=T)
splitting_index
library(caret)
library(caret)
set.seed(1234)
# Read in dataset
quality = read.csv("quality.csv")
#remove id column
quality <- quality[,-1]
# Table outcome
table(quality$PoorCare)
#create INDEX for training data set
splitting_index <- createDataPartition(quality$PoorCare , p=0.75 ,list=T)
splitting_index
# Look at structure
str(quality)
classes(splitting_index)
classes(quality)
Classes[splitting_index]
classes[splitting_index]
?classes[]
?classes
??classesToAM
?classes
??classes
?predict()
library(caret)
set.seed(1234)
# Read in dataset
quality = read.csv("quality.csv")
library(caret)
set.seed(1234)
# Read in dataset
quality = read.csv("quality.csv")
#remove id column
quality <- quality[,-1]
# Look at structure
str(quality)
# Table outcome
table(quality$PoorCare)
# Baseline accuracy (for percentage of split data)
98/131
#create(split) INDEX for training data set only. [It's not split the data]
splitting_index <- createDataPartition(quality$PoorCare , p=0.75 ,list=T)
splitting_index
#create train and test dataset
train_dataset <- quality[splitting_index,]
test_dataset <- quality[-splitting_index,]
#create(split) INDEX for training data set only. [It's not split the data]
splitting_index <- createDataPartition(quality$PoorCare , p=0.75 ,list=T)
splitting_index
#create(split) INDEX for training data set only. [It's not split the data]
splitting_index <- createDataPartition(quality$PoorCare , p=0.75 ,list=F)
splitting_index
#create train and test dataset
train_dataset <- quality[splitting_index,]
test_dataset <- quality[-splitting_index,]
#create(split) INDEX for training data set only. [It's not split the data]
splitting_index <- createDataPartition(quality$PoorCare , p=0.75 ,list=T)
splitting_index
class(splitting_index)
#create(split) INDEX for training data set only. [It's not split the data]
splitting_index <- createDataPartition(quality$PoorCare , p=0.75 ,list=F)
class(splitting_index)
#create(split) INDEX for training data set only. [It's not split the data]
splitting_index <- createDataPartition(quality$PoorCare , p=0.75 ,list=F)
splitting_index
class(splitting_index)
#create train and test dataset
train_dataset <- quality[splitting_index,]
test_dataset <- quality[-splitting_index,]
# Confusion matrix for threshold of 0.5
confuse_matrix_1 <- table(train_dataset$PoorCare, predictTrain > 0.5)
confuse_matrix_1
# Confusion matrix for threshold of 0.7
confuse_matrix_2 <- table(train_dataset$PoorCare, predictTrain > 0.7)
confuse_matrix_2
# Sensitivity and specificity
7/(7+18)
confuse_matrix_2
confuse_matrix_3
# Confusion matrix for threshold of 0.5
confuse_matrix_1 <- table(train_dataset$PoorCare, predictTrain > 0.5)
confuse_matrix_1
?prediction()
confusionMatrix(data = predictTrain , train_dataset$PoorCare)
confusionMatrix(data = predictTrain , reference = "PoorCare")
confusionMatrix(data = predictTrain , reference = train_dataset$PoorCare)
confusionMatrix(data =predictTrain)
confusionMatrix(data =predictTrain , reference = train_dataset)
confusionMatrix(data =predictTrain , reference = train_dataset$PoorCare)
confusionMatrix(data =predictTrain , reference = PoorCare)
confusionMatrix(data =predictTrain , reference = "PoorCare")
confusionMatrix(data = predictTrain , reference = train_dataset$PoorCare)
class( train_dataset$PoorCare)
?confusionMatrix()
confusionMatrix(data = predictTrain , reference = as.factor(train_dataset$PoorCare))
temp <- as.factor(train_dataset$PoorCare)
confusionMatrix(data = predictTrain , reference = temp)
predictTrain
train_dataset$PoorCare
count(train_dataset$PoorCare)
temp
predictTrain
str(train_dataset$PoorCare)
str(predictTrain)
max(train_dataset$PoorCare)
nrow(train_dataset$PoorCare)
confusionMatrix(data =  train_dataset$PoorCare , reference = predictTrain)
confusionMatrix(data =  train_dataset , reference = predictTrain)
class(predictTrain)
confusionMatrix(data =  train_dataset$PoorCare , reference = as.factor(predictTrain))
confusionMatrix(train_dataset$PoorCare , as.factor(as.integer(predictTrain)))
confusionMatrix(as.factors(train_dataset$PoorCare) , as.factor(as.integer(predictTrain)))
confusionMatrix(as.factor(train_dataset$PoorCare) , as.factor(as.integer(predictTrain)))
predictTrain
confusionMatrix(as.factor(train_dataset$PoorCare) , as.factor(as.integer(predictTrain>0.5)))
predictTrain
predictTrain>0.5
confusionMatrix(train_dataset$PoorCare , as.factor(as.integer(predictTrain>0.5)))
confusionMatrix(as.factor(train_dataset$PoorCare) , as.factor(as.integer(predictTrain>0.9)))
confusionMatrix(as.factor(train_dataset$PoorCare) , as.factor(as.integer(predictTrain>0.5)))
setwd("~/Documents/Data Science Master/ANA625/Final/Final_ANA625")
# Data Science Lifecycle
#     1. Get The Data -> gather data
#     2. Clean The Data -> handle: missing values, inaccurate data type, wrong observations
#     3. Explore The Data -> check for patterns, trends and transform
#     4. Model the Data -> make predictive models
#     5. Interpret -> explain the results
# set up libarires
packages <- c("dplyr", "plyr","ggformula", "caret", "pROC", "rpart", "rpart.plot", "psych", "car", "stats", "randomForest")
# Install package if there are not on machine
for (p in packages) {
if (require(p)){ install.packages(p) }
}
# Add libraries
# lapply(packages, FUN = library, character.only = T)
# Set up the orginal data set
master <- read.csv("vote_drough_1.csv",header=T)
#--------- Check for missing values
sum(is.na(master))
#--------- Check for variable data types
str(master)
master$target_2012 <- as.factor(master$target_2012)
master$target_2016 <- as.factor(master$target_2016)
mentor <- master[,1:8]
mentor$target <- master[,13] # target
pairs(mentor[,3:9], pch = 21, bg = c("red", "blue")[unclass(mentor[,9])])
# Compute Corrolation matrix
cor(mentor[,3:8]) # **** indepent variables have a high correlation
#----  See variable distributions
# Numerical Variable Frquency Distribution
multi.hist(mentor[,3:8], freq = T, bcol = "red")
library(MASS)
#----  See variable distributions
# Numerical Variable Frquency Distribution
multi.hist(mentor[,3:8], freq = T, bcol = "red")
library(psych)
#----  See variable distributions
# Numerical Variable Frquency Distribution
multi.hist(mentor[,3:8], freq = T, bcol = "red")
str(mentor)
# Make Full model
model.full <- glm(target ~ ., data = mentor[,3:9], family = "binomial")
# compute the vif
vif(model.full)
# Principal Component Analysis (Normalize variable by setting scale)
pca <- prcomp(mentor[,3:8], scale = T)
library(VIF)
# compute the vif
vif(model.full)
library(car)
# compute the vif
vif(model.full)
# See pca output (enginvector)
pca
# Get pca summary (std, prop variance and cumulative prop)
summary(pca)
# Make line Plot
plot(pca, type = "l", main = "PCA plot") # elbo at 3 select PC1 & PC2 & PC3
# Makee Scree Plot
biplot(pca, scale = 0)
# Makee Scree Plot
biplot(pca, scale = 0)
# Get the PCs
PCs <- round(pca$x[,1:3], 2)
# Get PCs summary
summary(PCs)
# SE data distribution
multi.hist(PCs, freq = T, bcol = "red")
# Create New data set with PCs
expert <- cbind(PCs, mentor)
# Set Seed
set.seed(1234)
# Create Training and Test Rows
#rows <- sample(nrow(expert), nrow(expert) * 0.80)
rows <- createDataPartition(expert$target, p = 0.80, list = F)
# Create Test and Train data
x1_train <- expert[rows,]
library(caret)
# Set Seed
set.seed(1234)
# Create Training and Test Rows
#rows <- sample(nrow(expert), nrow(expert) * 0.80)
rows <- createDataPartition(expert$target, p = 0.80, list = F)
# Create Test and Train data
x1_train <- expert[rows,]
x1_test <- expert[-rows,]
# Data to model
# keep_pc <- c("PC1", "PC2", "PC3","state", "target")
keep <-  c("None", "D0", "D1", "D2", "D3", "D4","state", "target") # Model with None Has better state + D0 + D1
#---- Create Model Binomial
# Make Null model
model.null <- glm(target ~ 1, data = x1_train[keep], family = "binomial")
# Make Full model
model.full <-  glm(target ~ ., data = x1_train[keep], family = "binomial")
# make Parsimonious Model to get best mod useing forward selection
model.step <- step(model.null, scope = list(lower = model.null, upper = model.full), direction = "forward")
# Set Seed
set.seed(1234)
# Create Training and Test Rows
#rows <- sample(nrow(expert), nrow(expert) * 0.80)
rows <- createDataPartition(expert$target, p = 0.80, list = F)
# Create Test and Train data
x1_train <- expert[rows,]
x1_test <- expert[-rows,]
#--- Check target Frequency
# table(x1_train$target)  # Train
# table(x1_test$target)   # Test
# Set Seed
set.seed(1234)
# Make Prediction
pred.glm <- predict(model.glm, x1_test, type = "response")
# Data to model
# keep_pc <- c("PC1", "PC2", "PC3","state", "target")
keep <-  c("None", "D0", "D1", "D2", "D3", "D4","state", "target") # Model with None Has better state + D0 + D1
#---- Create Model Binomial
# Make Null model
model.null <- glm(target ~ 1, data = x1_train[keep], family = "binomial")
# Make Full model
model.full <-  glm(target ~ ., data = x1_train[keep], family = "binomial")
# See Data summary
#summary(model.null)
#summary(model.full)
# make Parsimonious Model to get best mod useing forward selection
model.step <- step(model.null, scope = list(lower = model.null, upper = model.full), direction = "forward")
#model.step
# train model
model.glm <- glm(formula = target ~ state + None + D0 + D1, data = x1_train[keep], family = "binomial")
summary(model.glm)
# Set Seed
set.seed(1234)
# Make Prediction
pred.glm <- predict(model.glm, x1_test, type = "response")
# Create confusion marix
pred <- as.factor(ifelse(pred.glm > 0.63, 1, 0))
# Make Confusin matrix
confusionMatrix(data = pred, reference = x1_test$target, positive = "1", mode = "everything")
# Confusion matrix explained
# https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62
# Kappa explained
# https://thedatascientist.com/performance-measures-cohens-kappa-statistic/
# Data to model
# keep_pc <- c("PC1", "PC2", "PC3", "state", "target")
keep <-  c("None", "D0", "D1", "D2", "D3", "D4", "state", "target") # Model with None Has better state + D0 + D1
# Set seed
set.seed(1234)
# Train tree model
model.tree <- rpart(target ~ state + None + D1 + D0, data = x1_train[keep], method = "class", control = rpart.control(cp = .01, minsplit = 3), model = T)
library(rpart)
library(rpart.plot)
# Data to model
# keep_pc <- c("PC1", "PC2", "PC3", "state", "target")
keep <-  c("None", "D0", "D1", "D2", "D3", "D4", "state", "target") # Model with None Has better state + D0 + D1
# Set seed
set.seed(1234)
# Train tree model
model.tree <- rpart(target ~ state + None + D1 + D0, data = x1_train[keep], method = "class", control = rpart.control(cp = .01, minsplit = 3), model = T)
# Create a Dicision tree
rpart.plot(model.tree, type = 5, fallen.leaves = T)
# Make prediction
pred.tree <- predict(model.tree, x1_test, type = "class")
# Make confusion matrix
confusionMatrix(data = pred.tree, reference = x1_test$target, positive = "1", mode = "everything")
# Set Seed
set.seed(1234)
# Create random forest model with default mtry
model.forest <- randomForest(target ~ state + None + D1 + D0, data = x1_train[keep], ntree = 500)
library(randomForest)
# Set Seed
set.seed(1234)
# Create random forest model with default mtry
model.forest <- randomForest(target ~ state + None + D1 + D0, data = x1_train[keep], ntree = 500)
model.forest
# Make a prediction model
pred.forest <- predict(model.forest, x1_test[keep])
# Get AIC
mean(x1_test$target == pred.forest)
# Confusion matrix
confusionMatrix(data = pred.forest, reference = x1_test$target, positive = "1", mode = "everything")
#create trainControl for reuse
trainControl <- trainControl(method = "repeatedcv", number = 5 , repeats = 5)
# Create Model
model.knn <- train(target ~ state + D0 + D1 + None , x1_train ,
trControl = trainControl,
method = "knn",
tuneLength = 10,
preProcess = c("center","scale"))
plot(model.knn)
#test data set
pred.knn <- predict(model.knn, newdata = x1_test, type = "raw")
#Confusion Matrix with test data
confusionMatrix(as.factor(pred.knn), x1_test$target, mode = 'everything')
# Make ROC
roc.glm <- roc(x1_test$target, pred.glm)
library(rocc)
library(pROC)
# Make ROC
roc.glm <- roc(x1_test$target, pred.glm)
roc.tree <- roc(x1_test$target, as.numeric(pred.tree))
roc.forest <- roc(x1_test$target, as.numeric(pred.forest))
roc.knn <- roc(x1_test$target, as.numeric(pred.knn))
# Compute AUC
roc.glm$auc
roc.tree$auc
roc.forest$auc
roc.knn$auc
# PlotROC curve
plot(roc.glm, col = "green", print.auc=T, print.auc.y=.4, main = "Models' ROC Curve")
plot(roc.tree, col = "purple", print.auc=T, print.auc.y=.3, add = T)
plot(roc.forest, col = "brown", print.auc=T, print.auc.y=.2, add = T)
plot(roc.knn, col = "red", print.auc=T, print.auc.y=.1, add = T)
# Set legend
legend("bottomright", legend=c("Logistic", "Tree",
"Forest", "KNN"), col=c("green", "purple", "brown","red"), lwd=4, cex=0.9,
text.col = c("green", "purple", "brown","red"), bty='n')
plot(randomF_model)
#set up library
library(plyr)
library(ggplot2)
library(ROCR)
library(caret)
library(base)
#import data
vote_data <- read.csv("vote_drough.csv",header=T)
###############################
##### Data Pre processing #####
###############################
#Data structure check (vote_data year 2012)
names(vote_data)
str(vote_data)
# 0 is blue , 1 is red
table(vote_data$target)
table.target <- table(vote_data$target)
str(vote_data$target)
#baseline when the model predict all RED = 0.79
2384 / (643+2384)
#create data frame choose only necessary variables
working_data <- data.frame(county = vote_data$county , state = vote_data$state , None = vote_data$None , D0 = vote_data$D0 , D1 = vote_data$D1, D2 = vote_data$D2 , D3 = vote_data$D3 , D4 = vote_data$D4 , target = as.factor(vote_data$target))
levels(working_data$target) <- c("blue","red")
#splitting the data
#create(split) INDEX for training data set only. [It's not split the data]
set.seed(1234)
split_index <- createDataPartition(working_data$target,p=0.8,list=F)
train_data <- working_data[split_index,]
test_data <- working_data[-split_index,]
table(train_data$target)
table(test_data$target)
#############################################
############  create model  #################
#############################################
#create trainControl for reuse
trainControl <- trainControl(method = "repeatedcv", number = 5 , repeats = 5)
rf_trainControl <- trainControl(method="cv",number=5,classProbs=T,summaryFunction=twoClassSummary)
randomF_model <- train(target ~D0 + D1 + D2 + D3 + D4+  None , train_data ,
trControl = rf_trainControl ,
method = "ranger",
tuneLength = 4,
preProcess = c("center","scale"))
randomF_model <- train(target ~D0 + D1 +None +state , train_data ,
trControl = rf_trainControl ,
method = "ranger",
tuneLength = 4,
preProcess = c("center","scale"))
plot(randomF_model)
randomF_model
randomF_model <- train(target ~D0 + D1 +None +state , train_data ,
trControl = rf_trainControl ,
method = "rpart",
tuneLength = 4,
preProcess = c("center","scale"))
plot(randomF_model)
randomF_model
plot(randomF_model,main="Decision Tree's Tuning Parameter")
Decision_model <- train(target ~D0 + D1 +None +state , train_data ,
trControl = rf_trainControl ,
method = "rpart2",
tuneLength = 5,
preProcess = c("center","scale"),
metric="ROC")
plot(randomF_model,main="Decision Tree's Tuning Parameter")
plot(Decision_model,main="Decision Tree's Tuning Parameter")
Decision_model <- train(target ~D0 + D1 +None +state , train_data ,
trControl = rf_trainControl ,
method = "rpart2",
tuneLength = 10,
preProcess = c("center","scale"),
metric="ROC")
plot(Decision_model,main="Decision Tree's Tuning Parameter")
model.step
step(model.null, scope = list(lower = model.null, upper = model.full), direction = "forward")
Decision_model <- train(target ~D0 + D1 +None +state , train_data ,
trControl = rf_trainControl ,
method = "rpart",
tuneLength = 10,
preProcess = c("center","scale"),
metric="ROC")
plot(Decision_model,main="Decision Tree's Complexity Parameter ")
Decision_model
Decision_model <- train(target ~D0 + D1 +None +state , train_data ,
trControl = rf_trainControl ,
method = "rpart2",
tuneLength = 10,
preProcess = c("center","scale"),
metric="ROC")
plot(Decision_model,main="Decision Tree's Max Tree Depth")
Decision_model <- train(target ~D0 + D1 +None +state , train_data ,
trControl = rf_trainControl ,
method = "rpart2",
tuneLength = 10,
preProcess = c("center","scale"),
metric="ROC")
plot(Decision_model,main="Decision Tree's Max Tree Depth")
Decision_model
summary(model.glm)
