vote_data <- read.csv("vote_drough.csv",header=T)
vote_data
str(vote_data)
ranomF_cm
str(ranomF_cm)
ranomF_cm
class(ranomF_cm)
class(randomF_predicted)
randomF_predicted
# Prediction function, This function used to find other matrics
logistic_prediction <- prediction(as.numeric(randomF_predicted),test_dataset$Target)
#Create confusion matrix
randomF_cm <- confusionMatrix(test_dataset$Target,randomF_predicted)
# Prediction function, This function used to find other matrics
randomF_prediction <- prediction(as.numeric(randomF_predicted),test_dataset$Target)
#Find ROC
ROCR_logistic = performance(randomF_prediction, "tpr", "fpr")
#Find ROC
ROCR_randomF = performance(randomF_prediction, "tpr", "fpr")
ROCR_randomF
#Find AUC
auc.randomF <- performance(randomF_prediction,"auc")
auc.randomF.value <- auc.tmp.reduced@y.values[[1]] #area under curve
auc.randomF.value
#Plot ROC and AUC curve
plot(ROCR_randomF,colorize=T, main="ROC Curve")
plot(ROCR_randomF,colorize=T, main="ROC Curve")
mtext(paste("AUC: ",round(auc.randomF.value,4)),line = -8)
#lift chart
lift.randomF <- performance(randomF_prediction,"lift","rpp")
lift.randomF
#plot lift chart
plot(lift.randomF, main="lift curve", colorize=T)
str(vote_data)
#Checking outlier by boxplot
boxplot(working_data[,])
#Data structure check (vote_data)
names(vote_data)
str(vote_data)
table(vote_data)
table(vote_data$target)
#baseline when the model predict all BLUE = 0.60
643 / (643+2384)
#baseline when the model predict all RED = 0.60
2384 / (643+2384)
ggplot(vote_data,aes(x = D0)) + geom_histogram(bins=50) + ggtitle("D0 Distribution")
ggplot(vote_data,aes(x = D4)) + geom_histogram(bins=50) + ggtitle("D0 Distribution")
ggplot(vote_data,aes(x = D3)) + geom_histogram(bins=50) + ggtitle("D0 Distribution")
ggplot(vote_data,aes(x = D2)) + geom_histogram(bins=50) + ggtitle("D0 Distribution")
ggplot(vote_data,aes(x = D1)) + geom_histogram(bins=50) + ggtitle("D0 Distribution")
str(vote_data)
working_data_2 <- data.frame(county = vote_data$county, state = vote_data$state, D0 = vote_data$D0,D1 = vote_data$D1,D2 = vote_data$D2,D3 = vote_data$D3,
D4 = vote_data$D4,None = vote_data$None,Target = vote_data$target)
working_data_2
#splitting the data
#create(split) INDEX for training data set only. [It's not split the data]
splitting_index_2 <- createDataPartition(working_data_2$Target , p=0.80 ,list=F)
train_dataset_2 <- working_data[splitting_index_2,]
test_dataset_2 <- working_data[-splitting_index_2,]
Logistic_model_cv_2 <- train(Target ~ D0+D1+D2+D3+D4+None , train_dataset_2 , trControl = trainControl ,method="glm")
summary(Logistic_model_cv)
rf_model_cv_2 <- train(Target ~ D0+D1+D2+D3+D4+None , train_dataset_2 , trControl = trainControl ,method="ranger",)
rf_model_cv_2
plot(rf_model_cv_2)
#Plot ROC and AUC curve
plot(ROCR_logistic,colorize=T, main="ROC Curve")
#Plot ROC and AUC curve
plot(ROCR_randomF,colorize=T, main="ROC Curve")
logistic_predicted_2 <- predict(Logistic_model_cv_2,newdata = test_dataset,type="raw")
summary(logistic_predicted_2)
logistic_cm_2 <- confusionMatrix(test_dataset$Target,logistic_predicted_2)
logistic_cm_2
randomF_predicted_2 <- predict(rf_model_cv_2,newdata = test_dataset,type="raw") #vote data
randomF_cm_2 <- confusionMatrix(test_dataset$Target,randomF_predicted_2) #vote data
randomF_cm_2
logistic_cm_2 <- confusionMatrix(test_dataset$Target,logistic_predicted_2,mode="everything") #vote data
randomF_predicted_2 <- predict(rf_model_cv_2,newdata = test_dataset_2,type="raw") #vote data
randomF_cm_2 <- confusionMatrix(test_dataset_2$Target,randomF_predicted_2,,mode="everything") #vote data
randomF_cm_2
test_dataset_2
nrow(randomF_cm_2)
nrows(randomF_cm_2)
nrows(test_dataset_2)
nrow(test_dataset_2)
nrow(test_dataset_2)
nrow(working_data_2)
nrow(train_dataset_2)
nrow(test_dataset_2)
train_dataset_2 <- working_data_2[splitting_index_2,]
test_dataset_2 <- working_data_2[-splitting_index_2,]
nrow(train_dataset_2)
nrow(test_dataset_2)
#splitting the data
#create(split) INDEX for training data set only. [It's not split the data]
set.seed(1234)
splitting_index_2 <- createDataPartition(working_data_2$Target , p=0.80 ,list=F)
train_dataset_2 <- working_data_2[splitting_index_2,]
test_dataset_2 <- working_data_2[-splitting_index_2,]
Logistic_model_cv_2 <- train(Target ~ D0+D1+D2+D3+D4+None , train_dataset_2 , trControl = trainControl ,method="glm")
str(train_dataset_2)
str(working_data_2)
working_data_2 <- data.frame(county = vote_data$county, state = vote_data$state, D0 = vote_data$D0,D1 = vote_data$D1,D2 = vote_data$D2,D3 = vote_data$D3,
D4 = vote_data$D4,None = vote_data$None,Target = as.factor(vote_data$target))
str(working_data_2)
#splitting the data
#create(split) INDEX for training data set only. [It's not split the data]
set.seed(1234)
splitting_index_2 <- createDataPartition(working_data_2$Target , p=0.80 ,list=F)
train_dataset_2 <- working_data_2[splitting_index_2,]
test_dataset_2 <- working_data_2[-splitting_index_2,]
Logistic_model_cv_2 <- train(Target ~ D0+D1+D2+D3+D4+None , train_dataset_2 , trControl = trainControl ,method="glm")
rf_model_cv_2 <- train(Target ~ D0+D1+D2+D3+D4+None , train_dataset_2 , trControl = trainControl ,method="ranger",)
logistic_predicted_2 <- predict(Logistic_model_cv_2,newdata = test_dataset,type="raw")
logistic_cm_2 <- confusionMatrix(test_dataset$Target,logistic_predicted_2,mode="everything") #vote data
logistic_cm_2
randomF_predicted_2 <- predict(rf_model_cv_2,newdata = test_dataset_2,type="raw") #vote data
randomF_cm_2 <- confusionMatrix(test_dataset_2$Target,randomF_predicted_2,mode="everything") #vote data
randomF_cm_2
str(train_dataset_2)
Logistic_model_cv_2 <- train(Target ~ D0+D1+D2+D3+D4+None+state  , train_dataset_2 , trControl = trainControl ,method="glm")
summary(Logistic_model_cv)
logistic_predicted_2 <- predict(Logistic_model_cv_2,newdata = test_dataset,type="raw")
logistic_predicted_2 <- predict(Logistic_model_cv_2,newdata = test_dataset_2,type="raw")
summary(logistic_predicted_2) #vote data
rf_model_cv_2 <- train(Target ~ D0+D1+D2+D3+D4+None+state , train_dataset_2 , trControl = trainControl ,method="ranger",)
randomF_predicted_2 <- predict(rf_model_cv_2,newdata = test_dataset_2,type="raw") #vote data
randomF_cm_2 <- confusionMatrix(test_dataset_2$Target,randomF_predicted_2,mode="everything") #vote data
randomF_cm_2
model_temp <- train(Target ~ D0 + D1 + D2 + D3 + D4 + None , train_dataset , trControl = trainControl , method = "glm", preProcess = c("zv","center","scale","pca"))
model_temp
summary(Logistic_model_cv)
Logistic_model_cv
plot(model_temp)
model_temp2 <- train(Target ~ D0 + D1 + D2 + D3 + D4 + None , train_dataset , trControl = trainControl , method = "ranger", preProcess = c("zv","center","scale","pca"))
plot(model_temp2)
model_temp2
model_temp2 <- train(Target ~ D0 + D1 + D2 + D3 + D4 + None , train_dataset , trControl = trainControl , tuneLength = 10 ,method = "ranger", preProcess = c("zv","center","scale","pca"))
model_temp2 <- train(Target ~ D0 + D1 + D2 + D3 + D4 + None , train_dataset , trControl = trainControl , tuneLength = 4 ,method = "ranger", preProcess = c("zv","center","scale","pca"))
myGrid <- data.frame(mtry = c(1,2,3,4))
model_temp2
plot(model_temp2)
model_temp3 <- train(Target ~ D0 + D1 + D2 + D3 + D4 + None , train_dataset , trControl = trainControl , tuneGrid = myGrid ,method = "ranger", preProcess = c("zv","center","scale","pca"))
myGrid <- data.frame(mtry = c(1,2,3,4))
model_temp3 <- train(Target ~ D0 + D1 + D2 + D3 + D4 + None , train_dataset , trControl = trainControl,method = "ranger", tuneGrid = myGrid)
myGrid
model_temp3 <- train(Target ~ D0 + D1 + D2 + D3 + D4 + None , train_dataset , trControl = trainControl,method = "ranger", tuneGrid = data.frame(mtry = c(1,2,3,4)))
model_temp3 <- train(Target ~ D0 + D1 + D2 + D3 + D4 + None , train_dataset , trControl = trainControl,method = "ranger", tuneGrid = (mtry = c(1,2,3,4)))
model_temp2
library(plyr)
library(ggplot2)
library(ROCR)
#import data
vote_data <- read.csv("vote_drough.csv",header=T)
vote_data
#Data structure check (vote_data year 2012)
names(vote_data)
str(vote_data)
# 0 is blue , 1 is red
table(vote_data$target)
#baseline when the model predict all RED = 0.79
2384 / (643+2384)
data(iris)
names(iris)
names(iris) = tolower(names(iris))
names(iris)
split_index <- createDataPartition(iris$species,p=0.8,list=F)
iris.train <- iris[split_index,]
iris.test <- iris[-split_index,]
#train control
irisTrainControl = trainControl(method="cv")
lda.model <- train(species ~ . , data = iris.train , method="lda", trControl = irisTrainControl)
plot(lda.model)
lda.model
summary(lda.model)
#predict on test set
iris.pred <- predict(lda.model,iris.test)
iris.pred
?predict*()
?predict()
table(iris.pred , iris.test$species)
iris.test$species
iris.pred
table(iris.pred , iris.test$species)
pred.accuracy = round(mean(iris.pred == iris$species)*100,2)
pred.accuracy
pred.accuracy = round(mean(iris.pred == iris.test$species)*100,2)
pred.accuracy
#predict on test set
iris.pred <- predict(lda.model,iris.train)
table(iris.pred , iris.test$species)
table(iris.pred , iris.train$species)
pred.accuracy = round(mean(iris.pred == iris.train$species)*100,2)
pred.accuracy
pred.accuracy = mean(iris.pred == iris.train$species)
pred.accuracy
#model summary
lda.model
summary(lda.model)
data(Affairs, package = "AER")
set.seed(123)
affairs
Affairs
str(Affairs)
affairs.splitIndex <- createDataPartition(Affairs$affairs,p=0.8,list=F)
affairs.train <- Affairs[affairs.splitIndex,]
affairs.test <- Affairs[-affairs.splitIndex,]
affTrControl <- trainControl(summaryFunction = twoClassSummary , classProbs = T)
affModel <- train(Affairs$affairs ~ . , method = "pam", preProc = c("center","scale"),tuneGrid = c(1:4),metric="ROC",trControl=affTrControl)
affModel <- train(Affairs$affairs ~ . ,data=Affairs, method = "pam", preProc = c("center","scale"),tuneGrid = c(1:4),metric="ROC",trControl=affTrControl)
View(Affairs)
Affairs$ynaffair[Affairs$affairs > 0] <- 1
Affairs$ynaffair[Affairs$affairs == 0] <- 0
Affairs$ynaffair <- factor(Affairs$ynaffair, levels = c(0,1), labels = c("No", "Yes"))
affairs.splitIndex <- createDataPartition(Affairs$ynaffair,p=0.8,list=F)
affairs.train <- Affairs[affairs.splitIndex,]
affairs.test <- Affairs[-affairs.splitIndex,]
affTrControl <- trainControl(summaryFunction = twoClassSummary , classProbs = T)
nscGrid <- data.frame(.threshold = 0:4)
affModel <- train(Affairs$affairs ~ . ,data=Affairs,
method = "pam", preProc = c("center","scale"),
tuneGrid = nscGrid,metric="ROC",trControl=affTrControl)
affModel <- train(Affairs$ynaffair ~ . ,data=Affairs,
method = "pam", preProc = c("center","scale"),
tuneGrid = nscGrid,metric="ROC",trControl=affTrControl)
nscGrid <- data.frame(.threshold = 0:4)
affModel <- train(Affairs$ynaffair ~ . ,data=Affairs,
method = "pam", preProc = c("center","scale"),
tuneGrid = nscGrid,metric="ROC",trControl=affTrControl)
View(Affairs)
affModel <- train(ynaffair ~ . ,data=Affairs,
method = "pam", preProc = c("center","scale"),
tuneGrid = nscGrid,metric="ROC",trControl=affTrControl)
affModel
plot(affModel)
nscGrid <- data.frame(.threshold = 0:10)
affModel <- train(ynaffair ~ . ,data=Affairs,
method = "pam", preProc = c("center","scale"),
tuneGrid = nscGrid,metric="ROC",trControl=affTrControl)
plot(affModel)
View(nscGrid)
nscGrid <- data.frame(.threshold = 0:4)
affModel <- train(ynaffair ~ . ,data=Affairs,
method = "pam", preProc = c("center","scale"),
tuneGrid = nscGrid,metric="ROC",trControl=affTrControl)
plot(affModel)
nscGrid <- data.frame(.threshold = 0:10)
affModel <- train(ynaffair ~ . ,data=Affairs,
method = "pam", preProc = c("center","scale"),
tuneGrid = nscGrid,metric="ROC",trControl=affTrControl)
plot(affModel)
summary(affModel)
print(affModel)
?trainControl
vote_data
working_data <- data.frame(county = vote_date$county , state = vote_date$state , None = vote_date$None , D0 = vote_date$D0 , D1 = vote_date$D1, D2 = vote_date$D2 , D3 = vote_date$D3 , D4 = vote_date$D4 , target = vote_date$target)
working_data <- data.frame(county = vote_data$county , state = vote_data$state , None = vote_data$None , D0 = vote_data$D0 , D1 = vote_data$D1, D2 = vote_data$D2 , D3 = vote_data$D3 , D4 = vote_data$D4 , target = vote_data$target)
#splitting the data
#create(split) INDEX for training data set only. [It's not split the data]
set.seed(12)
#baseline when the model predict all RED = 0.79
2384 / (643+2384)
split_index <- createDataPartition(working_data$target,p=0.8,list=F)
train_data <- working_data[split_index,]
test_data <- working_data[-split_index,]
nrow(working_data)
nrow(train_data)
nrow(test_data)
#create model
trainControl <- trainControl(method = "cv", number = 5)
logistic_model <- train(Target ~ D0 + D1 + D2 + D3 + D4 + None , train_dataset ,
trControl = trainControl ,
method = "glm",
preProcess = c("zv","center","scale","pca"))
logistic_model
randomF_model <- train(Target ~ D0 + D1 + D2 + D3 + D4 + None , train_dataset ,
trControl = trainControl ,
method = "ranger",
preProcess = c("zv","center","scale","pca"))
randomF_model
plot(randomF_model)
knn_model <- train(Target ~ D0 + D1 + D2 + D3 + D4 + None , train_dataset ,
trControl = trainControl ,
method = "knn",
preProcess = c("zv","center","scale","pca"))
knn_model
plot(knn_model)
logistic_pred_train <- predict(logistic_model,type="response")
logistic_pred_train <- predict(logistic_model,type="raw")
logistic_pred_train
logistic_pred_test <- predict(logistic_model,newdata=test,type="raw")
logistic_pred_test <- predict(logistic_model,newdata=test_data,type="raw")
summary(logistic_pred_train)
summary(logistic_pred_test)
randomF_pred_train <- predict(randomF_model,type="response")
randomF_pred_train <- predict(randomF_model,type="raw")
randomF_pred_test <- predict(randomF_model,newdata=test_data,type="raw")
randomF_pred_train
summary(randomF_pred_train)
summary(randomF_pred_test)
summary(logistic_pred_test)
test_data
plot(randomF_model)
randomF_model <- train(Target ~ D0 + D1 + D2 + D3 + D4 + None , train_dataset ,
trControl = trainControl ,
method = "ranger",
tuneLength = 5,
preProcess = c("zv","center","scale","pca"))
randomF_model <- train(Target ~ D0 + D1 + D2 + D3 + D4 + None , train_dataset ,
trControl = trainControl ,
method = "ranger",
tuneLength = 4,
preProcess = c("zv","center","scale","pca"))
logistic_pred_train
class(logistic_pred_test)
class(test_data)
test_data$target
class(test_data$target)
confusionMatrix(data = logistic_pred_test,
reference = as.factor(class(test_data$target)),
mode='everything')
logistic_pred_test
test_data$target
confusionMatrix(data = as.factor(logistic_pred_test),
reference = as.factor(class(test_data$target)),
mode='everything')
confusionMatrix(as.factor(logistic_pred_test),
as.factor(class(test_data$target)),
mode='everything')
nrow(as.factor(logistic_pred_test),)
nrow(logistic_pred_test)
logistic_pred_test
nrow(as.factor(ogistic_pred_test))
nrow(as.factor(logistic_pred_test))
nrow(as.factor(test_data$target))
nrow(as.factor(predictions.class))
as.factor(predictions.class)
class(as.factor(predictions.class))
table(logistic_pred_test,test_data$target)
table(logistic_pred_train,train_data$target)
train_data
logistic_model <- train(Target ~ D0 + D1 + D2 + D3 + D4 + None , train_data ,
trControl = trainControl ,
method = "glm",
preProcess = c("zv","center","scale","pca"))
train_data
head*(train_data)
head(train_data)
logistic_model <- train(target ~ D0 + D1 + D2 + D3 + D4 + None , train_data ,
trControl = trainControl ,
method = "glm",
preProcess = c("zv","center","scale","pca"))
train-data$target
class(train_data)
#import data
vote_data <- read.csv("vote_drough.csv",header=T)
#Data structure check (vote_data year 2012)
names(vote_data)
#create data frame choose only necessary variables
working_data <- data.frame(county = vote_data$county , state = vote_data$state , None = vote_data$None , D0 = vote_data$D0 , D1 = vote_data$D1, D2 = vote_data$D2 , D3 = vote_data$D3 , D4 = vote_data$D4 , target = vote_data$target)
working_data
#splitting the data
#create(split) INDEX for training data set only. [It's not split the data]
set.seed(12)
split_index <- createDataPartition(working_data$target,p=0.8,list=F)
train_data <- working_data[split_index,]
test_data <- working_data[-split_index,]
train_data
test_data
head(test_data)
nrow(working_data)
nrow(train_data)
nrow(test_data)
#create trainControl for reuse
trainControl <- trainControl(method = "cv", number = 5)
class(working_data$target)
#create data frame choose only necessary variables
working_data <- data.frame(county = vote_data$county , state = vote_data$state , None = vote_data$None , D0 = vote_data$D0 , D1 = vote_data$D1, D2 = vote_data$D2 , D3 = vote_data$D3 , D4 = vote_data$D4 , target = as.factor(vote_data$target))
class(working_data$target)
#splitting the data
#create(split) INDEX for training data set only. [It's not split the data]
set.seed(12)
split_index <- createDataPartition(working_data$target,p=0.8,list=F)
train_data <- working_data[split_index,]
test_data <- working_data[-split_index,]
nrow(working_data)
nrow(train_data)
nrow(test_data)
#create trainControl for reuse
trainControl <- trainControl(method = "cv", number = 5)
logistic_model <- train(target ~ D0 + D1 + D2 + D3 + D4 + None , train_data ,
trControl = trainControl ,
method = "glm",
preProcess = c("zv","center","scale","pca"))
#predict
logistic_model
#predict
logistic_pred_train <- predict(logistic_model,type="raw")
logistic_pred_test <- predict(logistic_model,newdata=test_data,type="raw")
summary(logistic_pred_train)
summary(logistic_pred_test)
confusionMatrix(as.factor(logistic_pred_test),
as.factor(class(test_data$target)),
mode='everything')
nrow(test_data$target)
test_data$target
level(test_data$target)
levels(test_data$target)
levels(as.factor(logistic_pred_test))
confusionMatrix(as.factor(logistic_pred_test),
as.factor(class(test_data$target)),
mode='everything')
levels(test_data$target)
levels(as.factor(logistic_pred_test))
confusionMatrix(as.factor(logistic_pred_test),
test_data$target,
mode='everything')
table(logistic_pred_test,test_data$target)
table(logistic_pred_train,train_data$target)
randomF_model <- train(Target ~ D0 + D1 + D2 + D3 + D4 + None , train_data ,
trControl = trainControl ,
method = "ranger",
tuneLength = 4,
preProcess = c("zv","center","scale","pca"))
randomF_model <- train(target ~ D0 + D1 + D2 + D3 + D4 + None , train_data ,
trControl = trainControl ,
method = "ranger",
tuneLength = 4,
preProcess = c("zv","center","scale","pca"))
plot(randomF_model)
randomF_pred_train <- predict(randomF_model,type="raw")
randomF_pred_test <- predict(randomF_model,newdata=test_data,type="raw")
summary(randomF_pred_train)
summary(randomF_pred_test)
confusionMatrix(as.factor(randomF_pred_test),
test_data$target,
mode='everything')
knn_model <- train(target ~ D0 + D1 + D2 + D3 + D4 + None , train_data ,
trControl = trainControl ,
method = "knn",
preProcess = c("zv","center","scale","pca"))
plot(knn_model)
#prediction
knn_pred_test <- predict(knn_model,newdata=test_data,type="raw")
confusionMatrix(as.factor(knn_pred_test),test_data$target,mode='everything')
#Confusion Matrix with train data
confusionMatrix(as.factor(logistic_pred_test),train_data$target,mode='everything')
#Confusion Matrix with train data
confusionMatrix(as.factor(logistic_pred_train),train_data$target,mode='everything')
table(logistic_pred_test,test_data$target)
table(logistic_pred_test,test_data$target)
#Confusion Matrix with test data
confusionMatrix(as.factor(logistic_pred_test),test_data$target,mode='everything')
#Confusion Matrix with train data
confusionMatrix(as.factor(randomF_pred_train),train_data$target,mode='everything')
#Confusion Matrix with test data
confusionMatrix(as.factor(randomF_pred_test),test_data$target,mode='everything')
knn_model
print(knn_model)
#Confusion Matrix with test data
confusionMatrix(as.factor(knn_pred_test),test_data$target,mode='everything')
#Find AUC
auc.logis <- performance(logistic_prediction,"auc")
#Plot ROC and AUC curve
plot(ROCR_logistic,colorize=T, main="ROC Curve")
plot(ROCR_logistic,colorize=T, main="ROC Curve")
mtext(paste("AUC: ",round(auc.logistic.value,4)),line = -8)
logistic_model
#predict
#train data set
logistic_pred_train <- predict(logistic_model,type="raw")
summary(logistic_pred_train)
#Confusion Matrix with train data
confusionMatrix(as.factor(logistic_pred_train),train_data$target,mode='everything')
#test data set
logistic_pred_test <- predict(logistic_model,newdata=test_data,type="raw")
summary(logistic_pred_test)
#Confusion Matrix with test data
confusionMatrix(as.factor(logistic_pred_test),test_data$target,mode='everything')
plot(randomF_model)
randomF_model <- train(target ~ D0 + D1 + D2 + D3 + D4 + None , train_data ,
trControl = trainControl ,
method = "ranger",
tuneLength = 4,
preProcess = c("zv","center","scale","pca"))
plot(randomF_model)
plot(randomF_model)
#predict model with data
#train data set
randomF_pred_train <- predict(randomF_model,type="raw")
summary(randomF_pred_train)
#Confusion Matrix with train data
confusionMatrix(as.factor(randomF_pred_train),train_data$target,mode='everything')
#Confusion Matrix with test data
confusionMatrix(as.factor(randomF_pred_test),test_data$target,mode='everything')
knn_model <- train(target ~ D0 + D1 + D2 + D3 + D4 + None , train_data ,
trControl = trainControl ,
method = "knn",
preProcess = c("zv","center","scale","pca"))
print(knn_model)
plot(knn_model)
plot(knn_model)
#prediction
#train data set
knn_pred_train <- predict(knn_model,type="raw")
#Confusion Matrix with train data
confusionMatrix(as.factor(knn_pred_test),train_data$target,mode='everything')
#Confusion Matrix with train data
confusionMatrix(as.factor(knn_pred_train),train_data$target,mode='everything')
#test data set
knn_pred_test <- predict(knn_model,newdata=test_data,type="raw")
#Confusion Matrix with test data
confusionMatrix(as.factor(knn_pred_test),test_data$target,mode='everything')
