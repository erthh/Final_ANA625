confuse_matrix_1 <- table(train_dataset$PoorCare, predictTrain > 0.5)
confuse_matrix_1
?prediction()
confusionMatrix(data = predictTrain , train_dataset$PoorCare)
confusionMatrix(data = predictTrain , reference = "PoorCare")
confusionMatrix(data = predictTrain , reference = train_dataset$PoorCare)
confusionMatrix(data =predictTrain)
confusionMatrix(data =predictTrain , reference = train_dataset)
confusionMatrix(data =predictTrain , reference = train_dataset$PoorCare)
confusionMatrix(data =predictTrain , reference = PoorCare)
confusionMatrix(data =predictTrain , reference = "PoorCare")
confusionMatrix(data = predictTrain , reference = train_dataset$PoorCare)
class( train_dataset$PoorCare)
?confusionMatrix()
confusionMatrix(data = predictTrain , reference = as.factor(train_dataset$PoorCare))
temp <- as.factor(train_dataset$PoorCare)
confusionMatrix(data = predictTrain , reference = temp)
predictTrain
train_dataset$PoorCare
count(train_dataset$PoorCare)
temp
predictTrain
str(train_dataset$PoorCare)
str(predictTrain)
max(train_dataset$PoorCare)
nrow(train_dataset$PoorCare)
confusionMatrix(data =  train_dataset$PoorCare , reference = predictTrain)
confusionMatrix(data =  train_dataset , reference = predictTrain)
class(predictTrain)
confusionMatrix(data =  train_dataset$PoorCare , reference = as.factor(predictTrain))
confusionMatrix(train_dataset$PoorCare , as.factor(as.integer(predictTrain)))
confusionMatrix(as.factors(train_dataset$PoorCare) , as.factor(as.integer(predictTrain)))
confusionMatrix(as.factor(train_dataset$PoorCare) , as.factor(as.integer(predictTrain)))
predictTrain
confusionMatrix(as.factor(train_dataset$PoorCare) , as.factor(as.integer(predictTrain>0.5)))
predictTrain
predictTrain>0.5
confusionMatrix(train_dataset$PoorCare , as.factor(as.integer(predictTrain>0.5)))
confusionMatrix(as.factor(train_dataset$PoorCare) , as.factor(as.integer(predictTrain>0.9)))
confusionMatrix(as.factor(train_dataset$PoorCare) , as.factor(as.integer(predictTrain>0.5)))
#import data
vote_data <- read.csv("vote_drough.csv",header=T)
setwd("~/Documents/Data Science Master/ANA625/Final/Final_ANA625")
#set up library
library(plyr)
library(ggplot2)
library(ROCR)
library(caret)
#import data
vote_data <- read.csv("vote_drough.csv",header=T)
#create data frame choose only necessary variables
working_data <- data.frame(county = vote_data$county , state = vote_data$state , None = vote_data$None , D0 = vote_data$D0 , D1 = vote_data$D1, D2 = vote_data$D2 , D3 = vote_data$D3 , D4 = vote_data$D4 , target = as.factor(vote_data$target))
levels(working_data$target) <- c("blue","red")
#splitting the data
#create(split) INDEX for training data set only. [It's not split the data]
set.seed(1234)
split_index <- createDataPartition(working_data$target,p=0.8,list=F)
train_data <- working_data[split_index,]
test_data <- working_data[-split_index,]
table(train_data$target)
table(test_data$target)
hist(working_data$D0)
hist(working_data$D1)
hist(working_data$D2)
hist(working_data$D3)
hist(working_data$D4)
hist(working_data$None)
#create trainControl for reuse
trainControl <- trainControl(method = "repeatedcv", number = 5 , repeats = 5)
logistic_model <- train(target ~ D0 + D1 + D2 + D3 + D4 + None , train_data,
trControl = trainControl ,
method = "glm",
preProcess = c("center","scale"))
#predict
#train data set
logistic_pred_train <- predict(logistic_model,type="raw")
summary(logistic_pred_train)
#Confusion Matrix with train data
confusionMatrix(as.factor(logistic_pred_train),train_data$target,mode='everything')
#test data set
logistic_pred_test <- predict(logistic_model,newdata=test_data,type="raw")
summary(logistic_pred_test)
#Confusion Matrix with test data
logis_cm <- confusionMatrix(as.factor(logistic_pred_test),test_data$target,mode='everything')
#evaluate model
coef(logistic_model$finalModel)
#ROC and AUC
logistic_prediction <- prediction(as.numeric(logistic_pred_test),test_data$target)
logistic_perf <- performance(logistic_prediction, "tpr", "fpr")
plot(logistic_perf, main="ROC Curve")
#AUC
logistic_auc <- performance(rf_prediction,"auc")
logistic_auc_value <- logistic_auc@y.values[[1]] #area under curve
logistic_auc_value
###################################
######### Random Forrest ##########
###################################
#rf_trainControl <- trainControl(method = "cv", number = 5)
randomF_model <- train(target ~ D0 + D1 + D2 + D3 + D4 + None , train_data ,
trControl = trainControl ,
method = "ranger",
tuneLength = 4,
preProcess = c("center","scale"))
plot(randomF_model)
print(randomF_model)
#predict model with data
#train data set
randomF_pred_train <- predict(randomF_model,type="raw")
summary(randomF_pred_train)
#test data set
randomF_pred_test <- predict(randomF_model,newdata=test_data,type="raw")
summary(randomF_pred_test)
#Confusion Matrix with train data
confusionMatrix(as.factor(randomF_pred_train),train_data$target,mode='everything')
#Confusion Matrix with test data
randomF_cm <- confusionMatrix(as.factor(randomF_pred_test),test_data$target,mode='everything')
#ROC and AUC
rf_prediction <- prediction(as.numeric(randomF_pred_test),test_data$target)
rf_perf <- performance(rf_prediction, "tpr", "fpr")
plot(rf_perf, colorize=T,main="ROC Curve")
#AUC
randomF_auc <- performance(rf_prediction,"auc")
randomF_auc_value <- randomF_auc@y.values[[1]] #area under curve
randomF_auc_value
knn_model <- train(target ~ D0 + D1 + D2 + D3 + D4 + None , train_data ,
trControl = trainControl,
method = "knn",
tuneLength = 10,
preProcess = c("center","scale"))
#prediction
#train data set
knn_pred_train <- predict(knn_model,type="raw")
summary(knn_pred_train)
#Confusion Matrix with train data
confusionMatrix(as.factor(knn_pred_train),train_data$target,mode='everything')
#test data set
knn_pred_test <- predict(knn_model,newdata=test_data,type="raw")
#Confusion Matrix with test data
knn_cm <- confusionMatrix(as.factor(knn_pred_test),test_data$target,mode='everything')
#ROC and AUC
knn_prediction <- prediction(as.numeric(knn_pred_test),test_data$target)
knn_perf <- performance(knn_prediction, "tpr", "fpr")
plot(knn_perf, colorize=T,main="ROC Curve")
#AUC
knn_auc <- performance(knn_prediction,"auc")
knn_auc_value <- knn_auc@y.values[[1]] #area under curve
knn_auc_value
paste("AUC - Logistic: ", round(logistic_auc_value,4), "| Random Forrest: ",round(randomF_auc_value,4),
"| KNN: ",round(knn_auc_value,4))
paste("F1 Score - Logistic: ",round(logis_cm$byClass[7],4),"| Random Forrest: ", round(randomF_cm$byClass[7],4),
"| KNN: ",round(knn_cm$byClass[7],4))
paste("AUC - Logistic: ", round(logistic_auc_value,4), "| Random Forrest: ",round(randomF_auc_value,4),
"| KNN: ",round(knn_auc_value,4))
#AUC
logistic_auc <- performance(rf_prediction,"auc")
logistic_auc_value <- logistic_auc@y.values[[1]] #area under curve
logistic_auc_value
paste("AUC - Logistic: ", round(logistic_auc_value,4), "| Random Forrest: ",round(randomF_auc_value,4),
"| KNN: ",round(knn_auc_value,4))
paste("F1 Score - Logistic: ",round(logis_cm$byClass[7],4),"| Random Forrest: ", round(randomF_cm$byClass[7],4),
"| KNN: ",round(knn_cm$byClass[7],4))
paste("Accuracy - Logistic: ",round(logis_cm$overall[1],4),"| Random Forrest: ", round(randomF_cm$overall[1],4),
"| KNN: ",round(knn_cm$overall[1],4))
paste("Kappa - Logistic: ",round(logis_cm$byClass[2],4),"| Random Forrest: ", round(randomF_cm$overall[2],4),
"| KNN: ",round(knn_cm$overall[2],4))
#plot ROC
plot(knn_perf, col="blue",main="ROC Curve")
plot(knn_perf, col="blue",main="ROC Curve")
plot(rf_perf, col="salmon",add=T)
plot(logistic_perf, col="green",add=T)
mtext(paste("AUC(Logistic): ",round(knn_auc_value,4)),line = -2, side=1)
mtext(paste("AUC(Random Forrest): ",round(randomF_auc_value,4)),line = -3,side=1)
mtext(paste("AUC(KNN): ",round(knn_auc_value,4)),line = -4,side=1)
head(vote_data)
vote_data[,1:8]
#  Make Work data set
mentor <-vote_data[,1:8]
mentor.target <-vote_data[,13]
mentor
mentor_target <-vote_data[,13]
vote_data[,13]
vote_data[,12]
head(vote_data)
mentor_target <-vote_data[,11]
mentor_target
multi.hist(mentor[,1:8])
install.packages("psych")
library(psych)
multi.hist(mentor[,1:8])
multi.hist(mentor[,1:8],freq=T)
?multi.hist()
mentor[,1:8]
#  Make Work data set
mentor <-vote_data[,3:8]
multi.hist(mentor,freq=T)
multi.hist(mentor)
,freq=T
multi.hist(mentor,freq=T)
multi.hist(mentor,freq=T,col="salmon")
multi.hist(mentor,freq=T,color="salmon")
multi.hist(mentor,freq=T,bcol="salmon")
#  Make Work data set
mentor <-vote_data[,1:8]
multi.hist(mentor[,3:8],freq=T,bcol="salmon")
#pca
pca <- prcomp(mentor[,3:8])
pca
#pca
pca <- prcomp(mentor[,3:8],scale=T)
pca
summary(pca)
plot(pca)
plot(pca,type="l")
biplot(pca)
biplot(pca,scale=0)
pca
pca
summary(pca)
pca
pca$sdev
pca$x
pca$scale
pca$rotation
pca$x
# Get the PCs
PCs <-round(pca$x[,1:3], 2)
PCs
summary(PCs)
summary(pca)
pca
multi.hist(PCs, freq = T, bcol ="salmon")
?cbind
mentor
PCs
expert <- cbind(PCs,mentor)
head(expert)
mentor$target <-vote_data[,11]
multi.hist(mentor[,3:8],freq=T,bcol="salmon")
#pca
pca <- prcomp(mentor[,3:8],scale=T)
summary(pca)
plot(pca,type="l")
biplot(pca,scale=0)
# Get the PCs
PCs <-round(pca$x[,1:3], 2)
summary(PCs)
multi.hist(PCs, freq = T, bcol ="salmon")
expert <- cbind(PCs,mentor)
head(expert)
rows <-createDataPartition(expert$target, p =0.80, list = F)
# Create Test and Train
datax1_train <-expert[rows,]
x1_test <-expert[-rows,]
# Create Test and Train  data
x1_train <-expert[rows,]
x1_test <-expert[-rows,]
table(x1_train$target)
table(x1_test$target)
# Data to model
keep_pc <-c("PC1", "PC2", "PC3","state", "target")
keep <-c("None", "D0", "D1", "D2", "D3", "D4","state", "target")
# Model with NoneHas better state + D0 + D1
#---- Create Model Binomial
# Make Null model
model.null <-glm(target ~1, data = x1_train[keep], family ="binomial")
# Make Full model
model.full <-glm(target ~., data = x1_train[keep], family ="binomial")
model.null
coef(model.null)
coef(model.full)
model.full
model.step <-step(model.null, scope =list(lower = model.null, upper = model.full),direction ="forward")
model.step
summary(model.step)
model.x1_train <-glm(formula = target ~state +D0 +D1, data = x1_train[keep], family ="binomial")
model.x1_train
plot(knn_perf, col="blue",main="ROC Curve")
plot(rf_perf, col="salmon",add=T)
plot(logistic_perf, col="green",add=T)
mtext(paste("AUC(Logistic): ",round(knn_auc_value,4)),line = -2, side=1)
mtext(paste("AUC(Random Forrest): ",round(randomF_auc_value,4)),line = -3,side=1)
mtext(paste("AUC(KNN): ",round(knn_auc_value,4)),line = -4,side=1)
plot(knn_perf, col="blue",main="ROC Curve")
plot(rf_perf, col="salmon",add=T)
plot(logistic_perf, col="green",add=T)
mtext(paste("AUC(Logistic): ",round(knn_auc_value,4)),line = -2, side=1)
mtext(paste("AUC(Random Forrest): ",round(randomF_auc_value,4)),line = -3,side=1)
mtext(paste("AUC(KNN): ",round(knn_auc_value,4)),line = -4,side=1)
#plot box plot
featurePlot(x=working_data[3:8],y=working_data$target,scales=list(y=list(relation="free"),x=list(rot=90)))
plot(knn_perf, col="blue",main="ROC Curve")
plot(rf_perf, col="salmon",add=T)
plot(logistic_perf, col="green",add=T)
mtext(paste("AUC(Logistic): ",round(knn_auc_value,4)),line = -2, side=1)
mtext(paste("AUC(Random Forrest): ",round(randomF_auc_value,4)),line = -3,side=1)
mtext(paste("AUC(KNN): ",round(knn_auc_value,4)),line = -4,side=1)
plot(knn_perf, col="blue",main="ROC Curve")
plot(rf_perf, col="salmon",add=T)
plot(logistic_perf, col="green",add=T)
mtext(paste("AUC(Logistic): ",round(knn_auc_value,4)),line = -2, side=1)
mtext(paste("AUC(Random Forrest): ",round(randomF_auc_value,4)),line = -3,side=1)
mtext(paste("AUC(KNN): ",round(knn_auc_value,4)),line = -4,side=1)
varImp(logistic_model)
plot(varImp(logistic_model))
#feature selection in R
rfe_control <- rfeControl(functions=rfFuncs, method="cv", number=10)
table(test_data$target)
hist(working_data$D0)
hist(working_data$D1)
hist(working_data$D2)
hist(working_data$D3)
hist(working_data$D4)
hist(log(working_data$D4))
hist(working_data$D3)
hist(log(working_data$D3+1))
hist(log(working_data$D4+1))
hist(working_data$D2)
hist(working_data$D1)
hist(working_data$D0)
hist(log(working_data$D0+1))
hist(log(working_data$D1+1))
hist(log(working_data$D2+1))
hist(log(working_data$D3+1))
hist(log(working_data$D4+1))
hist(working_data$None)
hist(log(working_data$None+1))
hist(working_data$None)
plot(knn_model)
knn_model <- train(target ~ D0 + D1 + D2 + D3 + D4 + None , train_data ,
trControl = trainControl,
method = "knn",
tuneLength = 20,
preProcess = c("center","scale"))
plot(knn_model)
print(knn_model)
paste("AUC - Logistic: ", round(logistic_auc_value,4), "| Random Forrest: ",round(randomF_auc_value,4),
"| KNN: ",round(knn_auc_value,4))
paste("Accuracy - Logistic: ",round(logis_cm$overall[1],4),"| Random Forrest: ", round(randomF_cm$overall[1],4),
"| KNN: ",round(knn_cm$overall[1],4))
Affairs$ynaffair
data(Affairs, package = "AER")
# create binary outcome variable
Affairs$ynaffair[Affairs$affairs > 0] <- 1
Affairs$ynaffair[Affairs$affairs == 0] <- 0
Affairs$ynaffair <- factor(Affairs$ynaffair, levels = c(0,1), labels = c("No", "Yes"))
affairs.splitIndex <- createDataPartition(Affairs$ynaffair,p=0.8,list=F)
affairs.train <- Affairs[affairs.splitIndex,]
affairs.test <- Affairs[-affairs.splitIndex,]
affTrControl <- trainControl(summaryFunction = twoClassSummary , classProbs = T)
nscGrid <- data.frame(.threshold = 0:10)
affModel <- train(ynaffair ~ . ,data=Affairs,
method = "pam", preProc = c("center","scale"),
tuneGrid = nscGrid,metric="ROC",trControl=affTrControl)
print(affModel)
qdaModel <- train(ynaffair ~ . , data = Affairs,
method = "qda", preProc = c("center","scale"),
tuneLength = 10 ,
metric = "ROC",
trControl = addTrControl)
qdaModel <- train(ynaffair ~ . , data = Affairs,
method = "qda", preProc = c("center","scale"),
tuneLength = 10 ,
metric = "ROC",
trControl = affTrControl)
qdaModel
qdaModel <- train(ynaffair ~ . , data = Affairs,
method = "qda", preProc = c("center","scale"),
metric = "ROC",
trControl = affTrControl)
warnings()
#Last Class on Wednesday
qdaTrControl <- trainControl(method="cv",number=3,classProbs=T,summaryFunction=twoClassSummary)
qdaModel <- train(ynaffair ~ . , data = Affairs,
method = "qda", preProc = c("center","scale"),
metric = "ROC",
trControl = qdaTrControl)
nrow(Affairs)
#Last Class on Wednesday
qdaTrControl <- trainControl(method="cv",number=3,classProbs=T,summaryFunction=twoClassSummary)
qdaModel <- train(ynaffair ~ . , data = Affairs,
method = "qda",
preProc = c("center","scale"),
metric = "ROC",
trControl = qdaTrControl)
quadFunc= function (n, sigma, pp) {
sigma <- matrix(c(1, sigma, sigma, 2), 2, 2)
tmpData <- data.frame(mvrnorm(n = n, c(1, 0), sigma),
X3=rnorm(n), X4=sample(0:1, size=n, replace=TRUE,
prob=c(1-pp,pp)))    xSeq <- seq(-4, 4, length = 40)
plotGrid <- expand.grid(x = xSeq, y = xSeq)
zFoo <- function(x, y) -1 - 2 * x - 0 * y - 0.2 * x^2 + 2 * y^2
z2p <- function(x) 1/(1 + exp(-x))
tmpData$prob <- z2p(zFoo(tmpData$X1, tmpData$X2))
tmpData$class <- factor(ifelse(runif(length(tmpData$prob)) <=  tmpData$prob, "Class1", "Class2"))
tmpData
}
quadFunc= function (n, sigma, pp) {
sigma <- matrix(c(1, sigma, sigma, 2), 2, 2)
tmpData <- data.frame(mvrnorm(n = n, c(1, 0), sigma),
X3=rnorm(n), X4=sample(0:1, size=n, replace=TRUE,
prob=c(1-pp,pp)))
xSeq <- seq(-4, 4, length = 40)
plotGrid <- expand.grid(x = xSeq, y = xSeq)
zFoo <- function(x, y) -1 - 2 * x - 0 * y - 0.2 * x^2 + 2 * y^2
z2p <- function(x) 1/(1 + exp(-x))
tmpData$prob <- z2p(zFoo(tmpData$X1, tmpData$X2))
tmpData$class <- factor(ifelse(runif(length(tmpData$prob)) <=  tmpData$prob, "Class1", "Class2"))
tmpData
}
simulatedTrain <- quadFunc(1000, 0.7, 0.1)
simulatedTest <- quadFunc(500, 0.7, 0.1)
simulatedTrain <- quadFunc(1000, 0.7, 0.1)
quadFunc= function (n, sigma, pp) {
sigma <- matrix(c(1, sigma, sigma, 2), 2, 2)
tmpData <- data.frame(mvrnorm(n = n, c(1, 0), sigma),
X3=rnorm(n), X4=sample(0:1, size=n, replace=TRUE,
prob=c(1-pp,pp)))
xSeq <- seq(-4, 4, length = 40)
plotGrid <- expand.grid(x = xSeq, y = xSeq)
zFoo <- function(x, y) -1 - 2 * x - 0 * y - 0.2 * x^2 + 2 * y^2
z2p <- function(x) 1/(1 + exp(-x))
tmpData$prob <- z2p(zFoo(tmpData$X1, tmpData$X2))
tmpData$class <- factor(ifelse(runif(length(tmpData$prob)) <=  tmpData$prob, "Class1", "Class2"))
tmpData
}
simulatedTrain <- quadFunc(1000, 0.7, 0.1)
install.packages("rockchalk")
quadFunc= function (n, sigma, pp) {
sigma <- matrix(c(1, sigma, sigma, 2), 2, 2)
tmpData <- data.frame(mvrnorm(n = n, c(1, 0), sigma),
X3=rnorm(n), X4=sample(0:1, size=n, replace=TRUE,
prob=c(1-pp,pp)))
xSeq <- seq(-4, 4, length = 40)
plotGrid <- expand.grid(x = xSeq, y = xSeq)
zFoo <- function(x, y) -1 - 2 * x - 0 * y - 0.2 * x^2 + 2 * y^2
z2p <- function(x) 1/(1 + exp(-x))
tmpData$prob <- z2p(zFoo(tmpData$X1, tmpData$X2))
tmpData$class <- factor(ifelse(runif(length(tmpData$prob)) <=  tmpData$prob, "Class1", "Class2"))
tmpData
}
simulatedTrain <- quadFunc(1000, 0.7, 0.1)
library(rockchalk)
simulatedTrain <- quadFunc(1000, 0.7, 0.1)
simulatedTest <- quadFunc(500, 0.7, 0.1)
head(simulatedTrain)
qdaModel <- train(class ~ . , data = simulatedTrain,
method = "qda",
preProc = c("center","scale"),
metric = "ROC",
trControl = qdaTrControl)
qdaModel
plot(qdaModel)
summary(qdaModel)
str(Affairs)
nrow(Affairs)
qdaModel
qdaModel <- train(ynaffair ~ . , data = affairs.train,
method = "qda",
preProc = c("center","scale"),
metric = "ROC",
trControl = qdaTrControl)
qdaModel
qdaModel_aff
affairs.train
str(affairs.train)
qdaModel_aff <- train(ynaffair ~ . , data = affairs.train,
method = "qda",
preProc = c("center","scale"),
metric = "ROC",
trControl = qdaTrControl)
paste("AUC - Logistic: ", round(logistic_auc_value,4), "| Random Forrest: ",round(randomF_auc_value,4),
"| KNN: ",round(knn_auc_value,4))
paste("F1 Score - Logistic: ",round(logis_cm$byClass[7],4),"| Random Forrest: ", round(randomF_cm$byClass[7],4),
"| KNN: ",round(knn_cm$byClass[7],4))
plot(knn_perf, col="blue",main="ROC Curve")
plot(rf_perf, col="salmon",add=T)
plot(logistic_perf, col="green",add=T)
mtext(paste("AUC(Logistic): ",round(knn_auc_value,4)),line = -2, side=1)
mtext(paste("AUC(Random Forrest): ",round(randomF_auc_value,4)),line = -3,side=1)
mtext(paste("AUC(KNN): ",round(knn_auc_value,4)),line = -4,side=1)
hist(log(working_data$D1))
hist(log(working_data$D1+1))
hist(log(working_data$D2))
hist(log(working_data$D2+1))
hist((working_data$D1))
hist((working_data$D3))
hist((working_data$D4))
rfe_control
plot(rfe_control)
plot(varImp(logistic_model))
hist((working_data$D3))
hist((working_data$D2))
hist((working_data$D3))
view(working_data)
View(working_data)
paste("AUC - Logistic: ", round(logistic_auc_value,4), "| Random Forrest: ",round(randomF_auc_value,4),
"| KNN: ",round(knn_auc_value,4))
paste("Accuracy - Logistic: ",round(logis_cm$overall[1],4),"| Random Forrest: ", round(randomF_cm$overall[1],4),
"| KNN: ",round(knn_cm$overall[1],4))
# 0 is blue , 1 is red
table(vote_data$target)
prob.table(vote_data$target)
prob.table(table(vote_data$target))
prob(table(vote_data$target))
prob.table(vote_data$target))
prob.table(vote_data$target)
table.target <- as.table(vote_data$target
)
prob.table(vote_data$target)
prob.table(table.target)
library(base)
prob.table(table.target)
